{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "This notebook compares regression in C results to those from scipy and statsmodels for linear models. This includes both real-valued and complex-valued data.\n",
    "\n",
    "First define some functions that will help do the comparisons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regressioninc.linear.models import OLS, WLS, MEstimator\n",
    "from scipy.linalg import lstsq\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def tabulate_comparison(rinc_params, compare_params):\n",
    "    \"\"\"Tabulate the comparison of estimated parameters\"\"\"\n",
    "    diff = rinc_params - compare_params\n",
    "    data = {}\n",
    "    for ip in range(rinc_params.size):\n",
    "        data[f\"param {ip + 1}\"] = [rinc_params[ip], compare_params[ip], diff[ip]]\n",
    "    df = pd.DataFrame(data=data, index=[\"Regression in C\", \"Comparison\", \"Difference\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_actual(df, real_params, intercept=None):\n",
    "    \"\"\"Add the actual parameters to the tabulation\"\"\"\n",
    "    if intercept is not None:\n",
    "        real_params = list(real_params) + [intercept]\n",
    "    data = {f\"param {ip + 1}\": real_params[ip] for ip in range(len(real_params))}\n",
    "    df_actual = pd.DataFrame(data=data, index=[\"Actual\"])\n",
    "    return pd.concat((df_actual, df))\n",
    "\n",
    "\n",
    "def compare_ols(X, y):\n",
    "    \"\"\"Return parameters from regressioninc and scipy\"\"\"\n",
    "    # regression in C\n",
    "    rinc_model = OLS()\n",
    "    rinc_model.fit(X, y)\n",
    "    rinc_params = rinc_model.estimate.params\n",
    "    # scipy\n",
    "    scipy_params, _residues, _rank, _s = lstsq(X, y)\n",
    "    return tabulate_comparison(rinc_params, scipy_params)\n",
    "\n",
    "\n",
    "def compare_wls(X, y, weights):\n",
    "    \"\"\"Return parameters from regressionc and statsmodels\"\"\"\n",
    "    # regression in C\n",
    "    rinc_model = WLS()\n",
    "    rinc_model.fit(X, y, weights=weights)\n",
    "    rinc_params = rinc_model.estimate.params\n",
    "    # statsmodels\n",
    "    sm_wls = sm.WLS(y, X, weights=weights)\n",
    "    wls_results = sm_wls.fit()\n",
    "    return tabulate_comparison(rinc_params, wls_results.params)\n",
    "\n",
    "\n",
    "def compare_m_estimate(X, y, M1):\n",
    "    \"\"\"Return parameters from regressioninc and statsmodels\"\"\"\n",
    "    rinc_model = MEstimator(warm_start=True)\n",
    "    rinc_model.fit(X, y, M=M1)\n",
    "    rinc_estimate_1 = rinc_model.estimate.params\n",
    "    # statsmodels\n",
    "    sm_rlm = sm.RLM(y, X, M=M1)\n",
    "    rlm_result = sm_rlm.fit(maxiter=50, tol=1e-8, scale_est=\"mad\", conv=\"sresid\")\n",
    "    sm_rlm_1 = rlm_result.params\n",
    "    return tabulate_comparison(rinc_estimate_1, sm_rlm_1)\n",
    "\n",
    "\n",
    "def compare_mm_estimate(X, y, M1, M2):\n",
    "    \"\"\"Return parameters from regressioninc and statsmodels\"\"\"\n",
    "    rinc_model = MEstimator(warm_start=True)\n",
    "    rinc_model.fit(X, y, M=M1)\n",
    "    rinc_estimate_1 = rinc_model.estimate.params\n",
    "    rinc_model.fit(X, y, M=M2)\n",
    "    rinc_estimate_2 = rinc_model.estimate.params\n",
    "    # statsmodels\n",
    "    sm_rlm = sm.RLM(y, X, M=M1)\n",
    "    rlm_result = sm_rlm.fit(maxiter=50, tol=1e-8, scale_est=\"mad\", conv=\"sresid\")\n",
    "    sm_rlm_1 = rlm_result.params\n",
    "    rlm = sm.RLM(y, X, M=M2)\n",
    "    rlm_result = rlm.fit(\n",
    "        maxiter=50,\n",
    "        tol=1e-8,\n",
    "        scale_est=\"mad\",\n",
    "        conv=\"sresid\",\n",
    "        start_params=sm_rlm_1,\n",
    "    )\n",
    "    sm_rlm_2 = rlm_result.params\n",
    "    return tabulate_comparison(rinc_estimate_2, sm_rlm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-valued linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-08 21:02:53.307\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n",
      "\u001b[32m2023-10-08 21:02:53.314\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n",
      "\u001b[32m2023-10-08 21:02:53.315\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS\n",
      "                 param 1   param 2   param 3\n",
      "Actual            7.6000 -3.800000 -6.000000\n",
      "Regression in C   7.6254 -3.773379 -5.642764\n",
      "Comparison        7.6254 -3.773379 -5.642764\n",
      "Difference        0.0000  0.000000  0.000000\n",
      "\n",
      "\n",
      "WLS\n",
      "                      param 1       param 2       param 3\n",
      "Actual           7.600000e+00 -3.800000e+00 -6.000000e+00\n",
      "Regression in C  7.625400e+00 -3.773379e+00 -5.642764e+00\n",
      "Comparison       7.625400e+00 -3.773379e+00 -5.642764e+00\n",
      "Difference       8.881784e-16  1.776357e-15 -4.440892e-15\n",
      "\n",
      "\n",
      "M Estimator\n",
      "                      param 1       param 2       param 3\n",
      "Actual           7.600000e+00 -3.800000e+00 -6.000000e+00\n",
      "Regression in C  7.620207e+00 -3.789905e+00 -5.770261e+00\n",
      "Comparison       7.620207e+00 -3.789905e+00 -5.770261e+00\n",
      "Difference       3.376321e-11  1.362244e-10  9.304326e-10\n",
      "\n",
      "\n",
      "MM Estimator\n",
      "                      param 1       param 2       param 3\n",
      "Actual           7.600000e+00 -3.800000e+00 -6.000000e+00\n",
      "Regression in C  7.623338e+00 -3.810616e+00 -6.001904e+00\n",
      "Comparison       7.623338e+00 -3.810616e+00 -6.001904e+00\n",
      "Difference       2.664535e-15  4.440892e-15  3.552714e-15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from regressioninc.testing.real import generate_linear, add_gaussian_noise\n",
    "from regressioninc.linear.models import add_intercept\n",
    "\n",
    "np.random.seed(42)\n",
    "ADD_NOISE = True\n",
    "\n",
    "# generate the example data\n",
    "params = np.array([7.6, -3.8])\n",
    "intercept = -6\n",
    "X, y = generate_linear(params, 100, intercept=intercept)\n",
    "X = add_intercept(X)\n",
    "if ADD_NOISE:\n",
    "    y = add_gaussian_noise(y, 0, 3)\n",
    "\n",
    "print(\"OLS\")\n",
    "df = compare_ols(X, y)\n",
    "df = add_actual(df, params, intercept=intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nWLS\")\n",
    "weights = np.ones_like(y, dtype=float)\n",
    "df = compare_wls(X, y , weights)\n",
    "df = add_actual(df, params, intercept=intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nM Estimator\")\n",
    "M1 = sm.robust.norms.TukeyBiweight()\n",
    "df = compare_m_estimate(X, y, M1)\n",
    "df = add_actual(df, params, intercept=intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nMM Estimator\")\n",
    "M2 = sm.robust.norms.TrimmedMean()\n",
    "df = compare_mm_estimate(X, y, M1, M2)\n",
    "df = add_actual(df, params, intercept=intercept)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex-valued linear models\n",
    "\n",
    "Let's now compare regression in C linear models to other packages for complex-valued data. Scipy lstsq does support complex-valued data so no differences are expected there. However, for other models, results might not be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-08 21:03:01.315\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ringo_dingo/.cache/pypoetry/virtualenvs/regressioninc-B1eGejHw-py3.10/lib/python3.10/site-packages/numpy/core/_asarray.py:130: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n",
      "\u001b[32m2023-10-08 21:03:01.324\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n",
      "/home/ringo_dingo/.cache/pypoetry/virtualenvs/regressioninc-B1eGejHw-py3.10/lib/python3.10/site-packages/numpy/core/_asarray.py:130: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n",
      "\u001b[32m2023-10-08 21:03:01.331\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n",
      "\u001b[32m2023-10-08 21:03:01.332\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mregressioninc.linear.models\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m364\u001b[0m - \u001b[34m\u001b[1mEarly stopping criteria met, breaking\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS\n",
      "                            param 1             param 2               param 3\n",
      "Actual           0.500000+2.000000j -3.000000-1.000000j  20.000000+20.000000j\n",
      "Regression in C  0.416040+1.964015j -2.949279-0.955329j  21.072774+20.942814j\n",
      "Comparison       0.416040+1.964015j -2.949279-0.955329j  21.072774+20.942814j\n",
      "Difference       0.000000+0.000000j  0.000000+0.000000j  0.0000000+0.0000000j\n",
      "\n",
      "\n",
      "WLS\n",
      "                                    param 1                     param 2  \\\n",
      "Actual           5.000000e-01+2.000000e+00j -3.000000e+00-1.000000e+00j   \n",
      "Regression in C  4.160404e-01+1.964015e+00j -2.949279e+00-9.553286e-01j   \n",
      "Comparison       4.160404e-01+1.964015e+00j -2.949279e+00-9.553286e-01j   \n",
      "Difference      -2.553513e-15+8.881784e-16j  1.021405e-14-5.551115e-16j   \n",
      "\n",
      "                                    param 3  \n",
      "Actual           2.000000e+01+2.000000e+01j  \n",
      "Regression in C  2.107277e+01+2.094281e+01j  \n",
      "Comparison       2.107277e+01+2.094281e+01j  \n",
      "Difference       7.105427e-15-1.421085e-14j  \n",
      "\n",
      "\n",
      "M estimates\n",
      "                            param 1             param 2               param 3\n",
      "Actual           0.500000+2.000000j -3.000000-1.000000j  20.000000+20.000000j\n",
      "Regression in C  0.416527+1.961517j -2.951913-0.954506j  21.015214+20.959064j\n",
      "Comparison       0.409955+1.978972j -2.941540-0.953104j  21.276373+20.951180j\n",
      "Difference       0.006572-0.017455j -0.010372-0.001403j -0.2611580+0.0078840j\n",
      "\n",
      "\n",
      "M estimates\n",
      "                            param 1             param 2               param 3\n",
      "Actual           0.500000+2.000000j -3.000000-1.000000j  20.000000+20.000000j\n",
      "Regression in C  0.418300+1.978922j -2.951538-0.970235j  21.021943+20.607415j\n",
      "Comparison       0.390559+1.994663j -2.927038-0.967258j  21.382982+20.570365j\n",
      "Difference       0.027741-0.015742j -0.024500-0.002977j -0.3610390+0.0370500j\n",
      "\n",
      "\n",
      "MM estimates\n",
      "                            param 1             param 2               param 3\n",
      "Actual           0.500000+2.000000j -3.000000-1.000000j  20.000000+20.000000j\n",
      "Regression in C  0.407354+1.942318j -2.952344-0.945939j  21.039343+21.178977j\n",
      "Comparison       0.390559+1.994663j -2.927038-0.967258j  21.382982+20.570365j\n",
      "Difference       0.016796-0.052345j -0.025306+0.021320j -0.3436390+0.6086120j\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ringo_dingo/.cache/pypoetry/virtualenvs/regressioninc-B1eGejHw-py3.10/lib/python3.10/site-packages/numpy/core/_asarray.py:130: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  arr = array(a, dtype=dtype, order=order, copy=False, subok=subok)\n",
      "/home/ringo_dingo/.cache/pypoetry/virtualenvs/regressioninc-B1eGejHw-py3.10/lib/python3.10/site-packages/statsmodels/robust/robust_linear_model.py:255: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  start_params = np.asarray(start_params, dtype=np.double).squeeze()\n",
      "/home/ringo_dingo/.cache/pypoetry/virtualenvs/regressioninc-B1eGejHw-py3.10/lib/python3.10/site-packages/statsmodels/robust/robust_linear_model.py:174: RuntimeWarning: divide by zero encountered in divide\n",
      "  history['sresid'].append(tmp_results.resid / tmp_results.scale)\n"
     ]
    }
   ],
   "source": [
    "from regressioninc.testing.complex import ComplexGrid, generate_linear_grid\n",
    "from regressioninc.testing.complex import add_gaussian_noise\n",
    "from regressioninc.linear.models import add_intercept\n",
    "\n",
    "np.random.seed(42)\n",
    "ADD_NOISE = True\n",
    "\n",
    "params = np.array([0.5 + 2j, -3 - 1j])\n",
    "intercept = 20 + 20j\n",
    "grid_r1 = ComplexGrid(r1=0, r2=10, nr=11, i1=-5, i2=5, ni=11)\n",
    "grid_r2 = ComplexGrid(r1=-25, r2=-5, nr=11, i1=-5, i2=5, ni=11)\n",
    "X, y = generate_linear_grid(params, [grid_r1, grid_r2], intercept=intercept)\n",
    "X = add_intercept(X)\n",
    "if ADD_NOISE:\n",
    "    y = add_gaussian_noise(y, loc=(0, 0), scale=(3, 3))\n",
    "\n",
    "print(\"OLS\")\n",
    "df = compare_ols(X, y)\n",
    "df = add_actual(df, params, intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nWLS\")\n",
    "weights = np.ones_like(y, dtype=float)\n",
    "df = compare_wls(X, y , weights)\n",
    "df = add_actual(df, params, intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nM estimates\")\n",
    "M1 = sm.robust.norms.TukeyBiweight()\n",
    "df = compare_m_estimate(X, y, M1)\n",
    "df = add_actual(df, params, intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nM estimates\")\n",
    "M1 = sm.robust.norms.TrimmedMean()\n",
    "df = compare_m_estimate(X, y, M1)\n",
    "df = add_actual(df, params, intercept)\n",
    "print(df)\n",
    "\n",
    "print(\"\\n\\nMM estimates\")\n",
    "M1 = sm.robust.norms.TukeyBiweight()\n",
    "M2 = sm.robust.norms.TrimmedMean()\n",
    "df = compare_mm_estimate(X, y, M1, M2)\n",
    "df = add_actual(df, params, intercept)\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regressioninc-B1eGejHw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
